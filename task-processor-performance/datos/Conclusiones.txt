* Respecto del S.O.

- En el mismo hardware la diferencia entre linux y windows es mínima a favor de linux. 
  En el manejo de varios threads esa diferencia se agranda.   

- Una VM en mono thread utiliza sólo una parte de los cores al máximo, dejando margen para el resto (tengo 4 cores, utiliza el 25%)
- La VM le delega el manejo de threads al S.O. que se encarga de asignarle cores. La VM no tiene elección sobre que core se ejecutan las cosas.
- La carga de un monothread la balancea el S.O. (en windows se distribuye entre los cores, en linux carga un core)


* Respecto del código:

- Ejecutar un template method de una subclase es bastante costoso. Tarda el doble que si la subclase 
	define todo el comportamiento.  125871 ticks/s vs 270241
- Ejecutar un while(true) es menos costoso que un for, porque no requiere actualizar una variable. 270241 ticks/s vs 175457 ticks/s
- Ejecutar el for con la comparación "<" es levemente menos costoso que por "!=". 173061 ticks/s vs 161804 ticks/s

- Un thread puede cachear valores locales (como un flag) y no reaccionar si otro thread le cambio el valor
- El keyword "volatile" usado en el flag permite evitar ese cacheo.
- Volatile tiene un costo de performance en lectura que en el bucle principal reduce la performance drásticamente.
	Si se reduce la cantidad de lecturas, la performance aumenta considerablemente (de 360k a 36M)  

- Si los threads tienen que compartir una variable (no atomic) se molestan entre ellos por esperas. 
	Es mejor crear un contador para cada uno (dar a cada uno su propio recurso exclusivo) y evitar todo tipo de contacto,
	aunque sea memoria.
	
- Utilizar elementos de sincronización agrega costos de performance bastante caros y tiempos de bloqueo de 
	threads, aunque sea un único thread el que accede a los recursos. (puede ser menor al 1% de la performance sin sync)
- Si se utilizan elementos de Sync las esperas son mejor distribuidas entre los threads. 
	(Todos los threads esperan parecido). Seguramente por la fair policy de los locks.
	
- El try/catch agrega un pequeño costo de performance. De 1137386 t/s a 1022338 t/s
	
  

* Respecto a la cantidad de threads y VMs

- Ejecutando Vms en paralelo se logra mejor performance que varios threads en una sóla VM
- Utilizar varios threads (si no comparten recursos) aprovecha mejor el procesamiento aunque no tanto como 
	distintas VMs y requiere código más complejo
- Si se ejecutan más Vms que cores es posible lograr un pico mejor de performance, pero no es proporcional, 
	es apenas superior (y consume memoria proporcional). 914424 ticks/s (100% proc, 8VMs)


* Respecto de los tests
 
- Independientemente de cual sea la forma óptima de procesar, para implementar un procesador se debe elegir 
	un punto máximo, tomado como 1.0 y comparar contra ese las implementaciones. Ese punto debería ser 
	comparable, por lo que no importa que sea el mejor de todos los modelos posibles, si no el mejor entre 
	todas las comparaciones.

	Eso quiere decir que descartando la posibilidad de ejecutar varias vms a la vez, y tomando que se van a 
	ejecutar con threads y con unidades WorkUnit. El caso 0, debería ser el más rápido en esas condiciones. 
	Olvidando lo del mono-thread.
	
- El caso de mejor performance bajo las condiciones de testeabilidad es el de levantar en una vm tantos threads como cores
y no compartir estado. Con ellos se obtiene el valor más alto de performance para comparar luego con el resto 


Preguntas:


